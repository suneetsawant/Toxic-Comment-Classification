{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Toxic Comments.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [
        "7HezEbvZpiNN"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[View in Colaboratory](https://colab.research.google.com/github/suneetsawant/nlp/blob/master/Toxic_Comments.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "FM5Gl0DSfng8",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Import all the libraries "
      ]
    },
    {
      "metadata": {
        "id": "tsVXLNURUwpH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "fe6c6b5a-c611-48cc-85cd-a83868730367"
      },
      "cell_type": "code",
      "source": [
        "import pandas as pd \n",
        "import numpy as np \n",
        "import os,shutil\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.layers import CuDNNLSTM,Dense, Input, LSTM, Embedding, Dropout, Activation\n",
        "from keras.models import Model,Sequential\n",
        "import seaborn as sns\n",
        "from keras.models import model_from_json\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "%reload_ext autoreload\n",
        "%autoreload 2"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "mmcGd363fOz8",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Set up pydrive for uploading and downloading files (model and weights) \n",
        "\n",
        "The ***Drive()*** class gives method ***fileaction()***  to either upload or download a list of files \n",
        "\n",
        "### Usage :  \n",
        "      \n",
        "     To upload files named f1,f2  \n",
        "        Drive().fileaction([f1,f2],'up')\n",
        "     Similarly to download  \n",
        "        Drive().fileaction([f1,f2],'down')"
      ]
    },
    {
      "metadata": {
        "id": "51iW2yFKdA2c",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Authenticate and create the PyDrive client.\n",
        "!pip install -U -q PyDrive\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "class Drive(): \n",
        "  \n",
        "\n",
        "\n",
        "\n",
        "  \n",
        "  def __init__(self) :  \n",
        "    auth.authenticate_user()\n",
        "    gauth = GoogleAuth()\n",
        "    gauth.credentials = GoogleCredentials.get_application_default()\n",
        "    self.drive = GoogleDrive(gauth)\n",
        "\n",
        "\n",
        "  def fileaction(self,files,op='up') : \n",
        "    file_list = self.drive.ListFile({'q': \"'root' in parents and trashed=false\"}).GetList()\n",
        "    for filename in files:\n",
        "      flag = 0 \n",
        "\n",
        "      for file1 in file_list:\n",
        "        if (file1['title']) == filename :\n",
        "            if (op == 'up'and flag==0) : \n",
        "                file1.Delete()\n",
        "                self.upload(filename)\n",
        "                flag = 1\n",
        "\n",
        "            elif (op == 'down') : \n",
        "                self.download(filename,file1) \n",
        "\n",
        "      if(op=='up' and flag==0): \n",
        "            self.upload(filename)\n",
        "            flag = 1\n",
        "\n",
        "  def upload(self,filename) : \n",
        "      Uploadfile = self.drive.CreateFile({'title': filename})\n",
        "      Uploadfile.SetContentFile(filename)\n",
        "      Uploadfile.Upload()\n",
        "      print(\"Saved '{}' to Drive\".format(filename))\n",
        "\n",
        "  def download(self,filename,file1): \n",
        "      downloaded = self.drive.CreateFile({'id':file1['id']})\n",
        "      downloaded.GetContentFile(filename)\n",
        "      print(\"Downloaded '{}' from Drive\".format(filename))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "bSvANakCU-4o",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# **Download the Dataset**"
      ]
    },
    {
      "metadata": {
        "id": "MgBQojdKVSIs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 292
        },
        "outputId": "042c968f-20e3-42d3-e631-dce8dd7217ac"
      },
      "cell_type": "code",
      "source": [
        "!wget --header=\"Host: storage.googleapis.com\" --header=\"User-Agent: Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/65.0.3325.181 Safari/537.36\" --header=\"Accept: text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8\" --header=\"Accept-Language: en-US,en;q=0.9\" \"https://storage.googleapis.com/kaggle-competitions-data/kaggle/8076/train.csv.zip?GoogleAccessId=web-data@kaggle-161607.iam.gserviceaccount.com&Expires=1523554043&Signature=jxNQ%2BF1ridd29nYJPxVMQo3YM6axdT%2Bok0D0mCoQOFzCfpk8%2FJ1zF0jcpuD1Dy1gJbOfDnz2ndX9Aak4Hyc%2BZrmQCJRMSS3WwWg43%2B3AH99UntZk%2FHOmiEKCPFn5miNGe%2BTB4E6mfraJBtT7XBmX7vnye%2BOIhC1tpxFo6tpDPltgi6SZmmLMO76vXwKC9KU7eWguxnS9VTLuS4O1NK8cdwW2jucuQT8OXBu6C8rnfhpFb4wPqnUK7TXf80kd4zRNsAjy3czFP54pwBV9whBceIxW5arzdC4H2AJcPNYgRu4PQZ3i1niR1VpjuPTCCEb6xN0hmkeSFThLb2BK4mDmkg%3D%3D\" -O \"train.csv.zip\" -c\n",
        "!yes | unzip train.csv.zip \n",
        "\n",
        "   "
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2018-04-12 17:17:24--  https://storage.googleapis.com/kaggle-competitions-data/kaggle/8076/train.csv.zip?GoogleAccessId=web-data@kaggle-161607.iam.gserviceaccount.com&Expires=1523554043&Signature=jxNQ%2BF1ridd29nYJPxVMQo3YM6axdT%2Bok0D0mCoQOFzCfpk8%2FJ1zF0jcpuD1Dy1gJbOfDnz2ndX9Aak4Hyc%2BZrmQCJRMSS3WwWg43%2B3AH99UntZk%2FHOmiEKCPFn5miNGe%2BTB4E6mfraJBtT7XBmX7vnye%2BOIhC1tpxFo6tpDPltgi6SZmmLMO76vXwKC9KU7eWguxnS9VTLuS4O1NK8cdwW2jucuQT8OXBu6C8rnfhpFb4wPqnUK7TXf80kd4zRNsAjy3czFP54pwBV9whBceIxW5arzdC4H2AJcPNYgRu4PQZ3i1niR1VpjuPTCCEb6xN0hmkeSFThLb2BK4mDmkg%3D%3D\r\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 108.177.98.128, 2607:f8b0:400e:c01::80\r\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|108.177.98.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 27619914 (26M) [application/zip]\n",
            "Saving to: ‘train.csv.zip’\n",
            "\n",
            "train.csv.zip       100%[===================>]  26.34M  76.5MB/s    in 0.3s    \n",
            "\n",
            "2018-04-12 17:17:25 (76.5 MB/s) - ‘train.csv.zip’ saved [27619914/27619914]\n",
            "\n",
            "Archive:  train.csv.zip\n",
            "  inflating: train.csv               \n",
            "yes: standard output: Broken pipe\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "7HezEbvZpiNN",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Data Preprocessing "
      ]
    },
    {
      "metadata": {
        "id": "W5FBULF4Fjgc",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "  def prepareData(shuffle,valid_ratio) :\n",
        "      \n",
        "      dtrain = pd.read_csv('train.csv')\n",
        "      \n",
        "      dftrain, dfval = train_test_split(dtrain, test_size= valid_ratio,shuffle=shuffle)\n",
        "\n",
        "      classes = dftrain.columns[2:]\n",
        "      Xtrain = dftrain['comment_text'] \n",
        "      Ytrain = dftrain[classes].values \n",
        "\n",
        "      Xval = dfval['comment_text'] \n",
        "      Yval = dfval[classes].values \n",
        "      \n",
        "      return Xtrain,Ytrain,Xval,Yval\n",
        "    \n",
        "  def createTokens(vocab_size, data) :\n",
        "      tokenizer = Tokenizer(num_words = vocab_size)\n",
        "      tokenizer.fit_on_texts(data)\n",
        "      return tokenizer\n",
        "  \n",
        "  def tokenToSequence(data,tokenzier,max_len_sentence): \n",
        "      data = tokenizer.texts_to_sequences(data)\n",
        "      data = pad_sequences(data,maxlen=max_len_sentence)\n",
        "      return data   "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4onxT1sZ9-Nz",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Define the Model "
      ]
    },
    {
      "metadata": {
        "id": "gGZL17qZ99b0",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "  def Model(restore,loss,optimizer): \n",
        "      if(restore): return restoreModel(loss,optimizer)\n",
        "      else : return newModel(loss,optimizer)\n",
        " \n",
        "\n",
        "  def newModel(loss,optimizer) : \n",
        "      model = Sequential()\n",
        "      model.add(Embedding(vocab_size,256,input_length=max_len_sentence,name='Embedding'))\n",
        "      model.add(CuDNNLSTM(75,name =\"lstm\")) \n",
        "      \n",
        "      model.add(Dense(100,activation='relu',name='Dense1'))\n",
        "      model.add(Dropout(0.2,name='Dropout1')) \n",
        "      \n",
        "      model.add(Dense(6,activation='sigmoid',name='Dense2'))\n",
        "      model.compile (loss=loss,\n",
        "                        optimizer=optimizer)\n",
        "      return model \n",
        "  \n",
        "  def restoreModel(loss,optimizer): \n",
        "      \n",
        "      Drive().fileaction(['model.json','weights.hdf5'],'down') \n",
        "      with open('model.json', 'r') as json_file:\n",
        "          loaded_model_json = json_file.read()\n",
        "      model = model_from_json(loaded_model_json)\n",
        "      model.compile (loss=loss,\n",
        "                        optimizer=optimizer)\n",
        "      # load weights into new model\n",
        "      model.load_weights(\"weights.hdf5\")\n",
        "      print(\"Loaded saved model\")\n",
        "      \n",
        "      return model\n",
        "    \n",
        "  def buildModel(X,Y,epochs,batchsize,loss,optimizer,restore): \n",
        "    \n",
        "      model = Model(restore,loss,optimizer)      \n",
        "      filepath = \"weights.hdf5\"\n",
        "      checkpoint = ModelCheckpoint(filepath, monitor='loss',verbose=1, \n",
        "                                   save_best_only=True, mode='auto')\n",
        "      callbacks_list = [checkpoint]\n",
        "\n",
        "      model.fit(X,Y, batch_size=batch_size, epochs=epochs,callbacks=callbacks_list,verbose=1)\n",
        "\n",
        "      model_json = model.to_json()\n",
        "      with open(\"model.json\", \"w\") as json_file:\n",
        "          json_file.write(model_json) \n",
        "\n",
        "      Drive().fileaction(['model.json','weights.hdf5'],'up') \n",
        "      return model\n",
        "    \n",
        "  def trainModel(Xtrain,Ytrain,Xval,Yval,epochs,batchsize,loss,optimizer,restore): \n",
        "       \n",
        "      if(restore==1) : flag = 1 \n",
        "      else: flag = 0    \n",
        "\n",
        "      for i in range(epochs) :\n",
        "        \n",
        "        if(flag==0 and i>0): flag = 1\n",
        "        model = buildModel(Xtrain,Ytrain,1,batchsize,loss,optimizer,restore=flag)\n",
        "        trainScore = evaluateModel(Xtrain,Ytrain,model) \n",
        "        validScore = evaluateModel(Xval,Yval,model)\n",
        "        print('Training Score : {} - Validation Score:{}'.format(trainScore,validScore))\n",
        "      \n",
        "      model.summary()\n",
        "      print('Model is evaluated on metric ROC AUC')\n",
        "\n",
        "      return model\n",
        "    \n",
        "  def evaluateModel(X,Y,model): \n",
        "      preds = model.predict(X,verbose=1)\n",
        "      return roc_auc_score (Y,preds)\n",
        "    \n",
        " \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "XRPS2qvd9rvI",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Training Model"
      ]
    },
    {
      "metadata": {
        "id": "z_ro4UAWzkeR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1455
        },
        "outputId": "63697346-6e1d-4d60-ed96-1d23bba46bd7"
      },
      "cell_type": "code",
      "source": [
        "batch_size = 32\n",
        "epochs = 5\n",
        "loss='binary_crossentropy'\n",
        "optimizer='adam'\n",
        "restore = 1\n",
        "shuffle = True\n",
        "valid_ratio = 0.2\n",
        "vocab_size = 20000\n",
        "max_len_sentence = 200 \n",
        "\n",
        "Xtrain,Ytrain,Xval,Yval = prepareData(shuffle,valid_ratio)\n",
        "\n",
        "tokenizer = createTokens(vocab_size,Xtrain)\n",
        "\n",
        "Xtrain =   tokenToSequence(Xtrain,tokenizer,max_len_sentence)\n",
        "Xval   =   tokenToSequence(Xval,tokenizer,max_len_sentence)\n",
        "\n",
        "\n",
        "\n",
        "model = trainModel(Xtrain,Ytrain,Xval,Yval,epochs,batch_size,loss, optimizer,restore)\n"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloaded 'model.json' from Drive\n",
            "Downloaded 'weights.hdf5' from Drive\n",
            "Loaded saved model\n",
            "Epoch 1/1\n",
            " 36544/127656 [=======>......................] - ETA: 1:51 - loss: 0.1015"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "127656/127656 [==============================] - 152s 1ms/step - loss: 0.0701\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 00001: loss improved from inf to 0.07009, saving model to weights.hdf5\n",
            "Saved 'model.json' to Drive\n",
            "Saved 'weights.hdf5' to Drive\n",
            " 66784/127656 [==============>...............] - ETA: 25s"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "127656/127656 [==============================] - 53s 415us/step\n",
            "31915/31915 [==============================] - 14s 424us/step\n",
            "Training Score : 0.9858753898228395 - Validation Score:0.977025700566372\n",
            "Downloaded 'model.json' from Drive\n",
            "Downloaded 'weights.hdf5' from Drive\n",
            "Loaded saved model\n",
            "Epoch 1/1\n",
            "  7104/127656 [>.............................] - ETA: 2:48 - loss: 0.0402"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "127656/127656 [==============================] - 152s 1ms/step - loss: 0.0424\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 00001: loss improved from inf to 0.04243, saving model to weights.hdf5\n",
            "Saved 'model.json' to Drive\n",
            "Saved 'weights.hdf5' to Drive\n",
            " 66464/127656 [==============>...............] - ETA: 25s"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "127656/127656 [==============================] - 53s 413us/step\n",
            "31915/31915 [==============================] - 13s 412us/step\n",
            "Training Score : 0.9925772437965829 - Validation Score:0.9816158478853487\n",
            "Downloaded 'model.json' from Drive\n",
            "Downloaded 'weights.hdf5' from Drive\n",
            "Loaded saved model\n",
            "Epoch 1/1\n",
            "  7168/127656 [>.............................] - ETA: 2:54 - loss: 0.0327"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "127656/127656 [==============================] - 152s 1ms/step - loss: 0.0345\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 00001: loss improved from inf to 0.03454, saving model to weights.hdf5\n",
            "Saved 'model.json' to Drive\n",
            "Saved 'weights.hdf5' to Drive\n",
            " 66656/127656 [==============>...............] - ETA: 25s"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "127656/127656 [==============================] - 54s 424us/step\n",
            "31915/31915 [==============================] - 13s 416us/step\n",
            "Training Score : 0.9955035906486284 - Validation Score:0.9804562778844429\n",
            "Downloaded 'model.json' from Drive\n",
            "Downloaded 'weights.hdf5' from Drive\n",
            "Loaded saved model\n",
            "Epoch 1/1\n",
            "  7104/127656 [>.............................] - ETA: 2:48 - loss: 0.0265"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "127656/127656 [==============================] - 151s 1ms/step - loss: 0.0285\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 00001: loss improved from inf to 0.02848, saving model to weights.hdf5\n",
            "Saved 'model.json' to Drive\n",
            "Saved 'weights.hdf5' to Drive\n",
            " 65920/127656 [==============>...............] - ETA: 26s"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "127656/127656 [==============================] - 54s 421us/step\n",
            "31915/31915 [==============================] - 14s 429us/step\n",
            "Training Score : 0.9970893955034238 - Validation Score:0.9796250882099713\n",
            "Downloaded 'model.json' from Drive\n",
            "Downloaded 'weights.hdf5' from Drive\n",
            "Loaded saved model\n",
            "Epoch 1/1\n",
            "  7008/127656 [>.............................] - ETA: 2:53 - loss: 0.0193"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "127656/127656 [==============================] - 153s 1ms/step - loss: 0.0238\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 00001: loss improved from inf to 0.02376, saving model to weights.hdf5\n",
            "Saved 'model.json' to Drive\n",
            "Saved 'weights.hdf5' to Drive\n",
            " 66016/127656 [==============>...............] - ETA: 26s"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "127656/127656 [==============================] - 55s 429us/step\n",
            "31915/31915 [==============================] - 14s 427us/step\n",
            "Training Score : 0.9979360827714366 - Validation Score:0.978293122911761\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "Embedding (Embedding)        (None, 200, 256)          5120000   \n",
            "_________________________________________________________________\n",
            "lstm (CuDNNLSTM)             (None, 75)                99900     \n",
            "_________________________________________________________________\n",
            "Dense1 (Dense)               (None, 100)               7600      \n",
            "_________________________________________________________________\n",
            "Dropout1 (Dropout)           (None, 100)               0         \n",
            "_________________________________________________________________\n",
            "Dense2 (Dense)               (None, 6)                 606       \n",
            "=================================================================\n",
            "Total params: 5,228,106\n",
            "Trainable params: 5,228,106\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Model is evaluated on metric ROC AUC\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "lO0c1JZA-HiZ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "xtest = tokenizer.texts_to_sequences(Xtrain[2001:2010,])\n",
        "xtest = pad_sequences(xtest,maxlen=max_len_sentence) \n",
        "\n",
        "ytest = Ytrain[2001:2010,:]\n",
        "\n",
        "v =50\n",
        "xtest = X[:5000,:]\n",
        "ytest = Y[:5000,:]\n",
        "\n",
        "preds = model.predict(xtest)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "YVYFwHKSdmMX",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Test the model"
      ]
    },
    {
      "metadata": {
        "id": "hBaYO15AAWil",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 382
        },
        "outputId": "304c1a9b-6895-41a8-c745-c440aa991474"
      },
      "cell_type": "code",
      "source": [
        "!wget wget --header=\"Host: storage.googleapis.com\" --header=\"User-Agent: Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/65.0.3325.181 Safari/537.36\" --header=\"Accept: text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8\" --header=\"Accept-Language: en-US,en;q=0.9\" \"https://storage.googleapis.com/kaggle-competitions-data/kaggle/8076/test.csv.zip?GoogleAccessId=web-data@kaggle-161607.iam.gserviceaccount.com&Expires=1523721107&Signature=eJccX9d54GdNDdg%2B4iyiHf9L0SuOoej9SIDq2BRRIWL3V8X0l4%2FVXNxDLOAoxgOXNT7829tp2T%2BjMjoFVOABNdiqYeshPMFVK0Z%2B1bR%2BmolHAqzdpzdUnlCEkLjLEHc2l3DRscDLxxmXCZiPr1Cw3r%2F%2FPBT%2FfjHkNQvHCklaceeb7phAYj%2BEweYwtRJ%2B25F83ysn1BFalbT7IxvQax4MRzFdKs6%2F4X5bjPIZxViq1xIqrk9p1TwGgLwTUaAdtH0Sgsd6ne4sacfyKT6zREIWbkNNU0U%2BKHDStV3vo4VgB7V04nL9LvYPU6KAGKXKuqKDps7tTH3YgJ2sdAJB9tnn1w%3D%3D\" -O \"test.csv.zip\" -c\n",
        "!unzip -o test.csv.zip\n",
        "dtest = pd.read_csv('test.csv')\n",
        "Xtest = dtest['comment_text']\n",
        "dtest.info()\n"
      ],
      "execution_count": 118,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2018-04-11 18:23:56--  http://wget/\r\n",
            "Resolving wget (wget)... failed: Name or service not known.\r\n",
            "wget: unable to resolve host address ‘wget’\r\n",
            "--2018-04-11 18:23:56--  https://storage.googleapis.com/kaggle-competitions-data/kaggle/8076/test.csv.zip?GoogleAccessId=web-data@kaggle-161607.iam.gserviceaccount.com&Expires=1523721107&Signature=eJccX9d54GdNDdg%2B4iyiHf9L0SuOoej9SIDq2BRRIWL3V8X0l4%2FVXNxDLOAoxgOXNT7829tp2T%2BjMjoFVOABNdiqYeshPMFVK0Z%2B1bR%2BmolHAqzdpzdUnlCEkLjLEHc2l3DRscDLxxmXCZiPr1Cw3r%2F%2FPBT%2FfjHkNQvHCklaceeb7phAYj%2BEweYwtRJ%2B25F83ysn1BFalbT7IxvQax4MRzFdKs6%2F4X5bjPIZxViq1xIqrk9p1TwGgLwTUaAdtH0Sgsd6ne4sacfyKT6zREIWbkNNU0U%2BKHDStV3vo4VgB7V04nL9LvYPU6KAGKXKuqKDps7tTH3YgJ2sdAJB9tnn1w%3D%3D\r\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 74.125.141.128, 2607:f8b0:400c:c06::80\r\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|74.125.141.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 416 Requested range not satisfiable\n",
            "\n",
            "    The file is already fully retrieved; nothing to do.\n",
            "\n",
            "Archive:  test.csv.zip\n",
            "  inflating: test.csv                \n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 153164 entries, 0 to 153163\n",
            "Data columns (total 2 columns):\n",
            "id              153164 non-null object\n",
            "comment_text    153164 non-null object\n",
            "dtypes: object(2)\n",
            "memory usage: 2.3+ MB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "gxYDlnpUAq30",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "Xtest = tokenizer.texts_to_sequences(Xtest)\n",
        "Xtest = pad_sequences(Xtest,maxlen=max_len_sentence) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "q3dunceBA3vq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "563120d7-f2c7-446d-8c41-9665060a9d5b"
      },
      "cell_type": "code",
      "source": [
        "preds = model.predict(Xtest,verbose=1)\n",
        "preds[preds>=0.5] = 1\n",
        "preds[preds<0.5] = 0\n",
        "preds.shape"
      ],
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "153164/153164 [==============================] - 59s 388us/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(153164, 6)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 114
        }
      ]
    },
    {
      "metadata": {
        "id": "_j-6HvukBKec",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "result = pd.DataFrame(preds,columns = classes)\n",
        "result['id'] = dtest['id']\n",
        "result.to_csv('result.csv',index=False)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "QLTvPVr4B5bB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "outputId": "c5838d95-9502-4d5c-a392-e48c340a1798"
      },
      "cell_type": "code",
      "source": [
        "result.info()"
      ],
      "execution_count": 116,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 153164 entries, 0 to 153163\n",
            "Data columns (total 7 columns):\n",
            "toxic            153164 non-null float32\n",
            "severe_toxic     153164 non-null float32\n",
            "obscene          153164 non-null float32\n",
            "threat           153164 non-null float32\n",
            "insult           153164 non-null float32\n",
            "identity_hate    153164 non-null float32\n",
            "id               153164 non-null object\n",
            "dtypes: float32(6), object(1)\n",
            "memory usage: 4.7+ MB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "u2rp4LB5DfqR",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download('result.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "XdlY6luuDrFp",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}